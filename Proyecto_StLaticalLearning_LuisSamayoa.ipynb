{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad Galileo\n",
    "# Maestria en Ciencia de datos\n",
    "# Statical Learning I\n",
    "\n",
    "### Luis Alejandro Samayoa Alvarado\n",
    "### 19002957\n",
    "\n",
    "\n",
    "# Proyecto de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias\n",
    "\n",
    "Iniciaremos cargando las diferentes librerias de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as mt\n",
    "import tensorflow as tf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Middle</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "5            6                                   Moran, Mr. James   NaN   \n",
       "6            7                            McCarthy, Mr. Timothy J  54.0   \n",
       "7            8                     Palsson, Master. Gosta Leonard   2.0   \n",
       "8            9  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0   \n",
       "9           10                Nasser, Mrs. Nicholas (Adele Achem)  14.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       "1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       "3      1      0            113803  53.1000  C123        S           Upper   \n",
       "4      0      0            373450   8.0500   NaN        S           Lower   \n",
       "5      0      0            330877   8.4583   NaN        Q           Lower   \n",
       "6      0      0             17463  51.8625   E46        S           Upper   \n",
       "7      3      1            349909  21.0750   NaN        S           Lower   \n",
       "8      0      2            347742  11.1333   NaN        S           Lower   \n",
       "9      1      0            237736  30.0708   NaN        C          Middle   \n",
       "\n",
       "  passenger_sex passenger_survived  \n",
       "0             M                  N  \n",
       "1             F                  Y  \n",
       "2             F                  Y  \n",
       "3             F                  Y  \n",
       "4             M                  N  \n",
       "5             M                  N  \n",
       "6             M                  N  \n",
       "7             M                  N  \n",
       "8             F                  Y  \n",
       "9             F                  Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic = pd.read_csv(\"titanic.csv\")\n",
    "Titanic.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores faltantes de Age con la mediana\n",
    "Titanic[\"Age\"] = Titanic[\"Age\"].fillna(Titanic[\"Age\"].median());\n",
    "Titanic[\"Age\"].isnull().sum()\n",
    "\n",
    "# Limpiar el sexo de los pasajeros, Sex = 1 si es mujer\n",
    "Titanic[\"Sex\"] = (Titanic[\"passenger_sex\"] == 'F').astype(np.float)\n",
    "\n",
    "# Limpiar el embarcamiento\n",
    "Titanic[\"Embarked_cleaned\"] = np.where(Titanic[\"Embarked\"]==\"S\", 1, \n",
    "    np.where(Titanic[\"Embarked\"]==\"C\", 2, np.where(Titanic[\"Embarked\"]==\"Q\", 3, 0)))\n",
    "\n",
    "# Asignar la clase de pasajero\n",
    "Titanic[\"Pclass_cleaned\"] = np.where(Titanic[\"passenger_class\"]==\"Lower\", 1, \n",
    "    np.where(Titanic[\"passenger_class\"]==\"Middle\", 2, np.where(Titanic[\"passenger_class\"]==\"Upper\", 3, 0)))\n",
    "\n",
    "\n",
    "# Obtener las variables para los modelos\n",
    "target = [\"passenger_survived\"]\n",
    "numeric_fields = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sex\", \"Embarked_cleaned\", \"Pclass_cleaned\"]\n",
    "#numeric_fields = [\"Age\", \"Fare\", \"Sex\", \"Embarked_cleaned\", \"Pclass_cleaned\"]\n",
    "y = (Titanic[target].values == 'Y').astype(np.float)\n",
    "X = Titanic[numeric_fields].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 7), (143, 7), (179, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separación de los datos de entrenamiento-validación y de prueba \n",
    "X_train_cv, X_test, y_train_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separación de los datos de entrenamiento y de validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_cv, y_train_cv, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Naive Bayes\n",
    "\n",
    "Es un clasificador probabilístico fundamentado en el teorema de Bayes, asume que la presencia o ausencia de una característica particular no está relacionada con la presencia o ausencia de cualquier otra característica, dada la clase variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x, y, lista):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "    model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "    model.fit(x[:, lista],y)\n",
    "    y_pred = model.predict(X_val[:, lista])\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy=accuracy_score(y_val, y_pred, normalize=True)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1=f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "    from sklearn.metrics import recall_score\n",
    "    recall=recall_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    precision=average_precision_score(y_val, y_pred)\n",
    "      \n",
    "    return model, lista, accuracy, f1, recall, precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " 0.7622377622377622,\n",
       " 0.7635399083674946,\n",
       " 0.7622377622377622,\n",
       " 0.6051927239427239)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista1=[0,1,2,3,4,5, 6]\n",
    "naive_bayes(X_train,y_train, lista1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " [0, 2, 3, 4, 5, 6],\n",
       " 0.7762237762237763,\n",
       " 0.7762237762237763,\n",
       " 0.7762237762237763,\n",
       " 0.622092193520765)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista2=[0,2,3,4,5, 6]\n",
    "naive_bayes(X_train,y_train, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " [0, 3, 4, 5, 6],\n",
       " 0.8111888111888111,\n",
       " 0.8101905868971644,\n",
       " 0.8111888111888111,\n",
       " 0.6712697679678812)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista3=[0,3,4,5, 6]\n",
    "naive_bayes(X_train,y_train, lista3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " [0, 2, 4, 5, 6],\n",
       " 0.7762237762237763,\n",
       " 0.7774493255223478,\n",
       " 0.7762237762237763,\n",
       " 0.6229020979020978)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista4=[0,2,4,5, 6]\n",
    "naive_bayes(X_train,y_train, lista4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo segun el clasificador Naive Bayes es el que incluye a las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print(lista3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(X, y, C_param): \n",
    "    svm_model = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(C = C_param, kernel='rbf', gamma = 0.01, tol = 0.001, max_iter = 5000))\n",
    "    ])\n",
    "\n",
    "    modelo=svm_model.fit(X, y.reshape(len(y), ))\n",
    "    \n",
    "    y_pred = svm_model.predict(X_val)\n",
    "    resultados=mt.accuracy_score(y_val, y_pred, normalize=True), mt.f1_score(y_val, y_pred), mt.precision_score(y_val, y_pred), mt.recall_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    return modelo, resultados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "      steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "   max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False))]),\n",
       " (0.8181818181818182,\n",
       "  0.7592592592592592,\n",
       "  0.7884615384615384,\n",
       "  0.8181818181818182))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = 1\n",
    "svm_train(X_train, y_train, C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "      steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "   max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False))]),\n",
       " (0.8181818181818182,\n",
       "  0.7592592592592592,\n",
       "  0.7884615384615384,\n",
       "  0.8181818181818182))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2 = 10\n",
    "svm_train(X_val, y_val, C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbol_segmentacion(X_train, X_val, y_train, y_val, profundidad): \n",
    "    tree_one = tree.DecisionTreeClassifier(max_depth = profundidad)\n",
    "    tree_one = tree_one.fit(X_train, y_train)\n",
    "    Escore = tree_one.score(X_train, y_train)\n",
    "    tree_one.fit(X_train,y_train)\n",
    "    y_pred = tree_one.predict(X_train)\n",
    "    \n",
    "    trainMetrics = [mt.accuracy_score(y_train, y_pred, normalize=True), \n",
    "                    mt.f1_score(y_train, y_pred), \n",
    "                    mt.precision_score(y_train, y_pred), \n",
    "                    mt.recall_score(y_train, y_pred, average='weighted')]\n",
    "    \n",
    "    y_pred = tree_one.predict(X_val)\n",
    "    validationMetrics = [mt.accuracy_score(y_val, y_pred, normalize=True), \n",
    "                    mt.f1_score(y_val, y_pred), \n",
    "                    mt.precision_score(y_val, y_pred), \n",
    "                    mt.recall_score(y_val, y_pred, average='weighted')]\n",
    "    # Devolver el objeto del modelo, métricas en datos de entrenamiento, métricas en datos de validación\n",
    "    return trainMetrics, validationMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7996485061511424,\n",
       "  0.6503067484662577,\n",
       "  0.9298245614035088,\n",
       "  0.7996485061511424],\n",
       " [0.8181818181818182,\n",
       "  0.7234042553191489,\n",
       "  0.8947368421052632,\n",
       "  0.8181818181818182])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol_segmentacion(X_train, X_val, y_train, y_val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8330404217926186,\n",
       "  0.760705289672544,\n",
       "  0.8162162162162162,\n",
       "  0.8330404217926186],\n",
       " [0.8321678321678322, 0.7735849056603773, 0.82, 0.8321678321678322])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol_segmentacion(X_train, X_val, y_train, y_val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8383128295254832, 0.77, 0.8191489361702128, 0.8383128295254832],\n",
       " [0.8391608391608392,\n",
       "  0.7850467289719627,\n",
       "  0.8235294117647058,\n",
       "  0.8391608391608392])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol_segmentacion(X_train, X_val, y_train, y_val, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8787346221441125,\n",
       "  0.8140161725067385,\n",
       "  0.949685534591195,\n",
       "  0.8787346221441125],\n",
       " [0.7902097902097902, 0.7, 0.7954545454545454, 0.7902097902097902])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol_segmentacion(X_train, X_val, y_train, y_val, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_reg_logistica(Xtrain, Ytrain, lr, lambda_val, epochs, tag):\n",
    "    import time\n",
    "    \n",
    "    # Obtener features de Xtrain y número de  ejemplos\n",
    "    m, k = Xtrain.shape\n",
    "    \n",
    "    # Agregar la columna de 1's al Xtrain\n",
    "    #Xtrain = np.column_stack((np.ones(m), Xtrain))\n",
    "    \n",
    "    # Crear el grafo\n",
    "    # -------------------------------------------------------------------------\n",
    "    tf.reset_default_graph()\n",
    "    g = tf.Graph()\n",
    "    # Definimos tensores y operaciones en g\n",
    "    with g.as_default():\n",
    "        # Creando los placeholders\n",
    "        X = tf.placeholder(tf.float32, shape = (None, k), name = \"X\")\n",
    "        Ylabels = tf.placeholder(tf.float32, name = \"Ylabels\")\n",
    "\n",
    "        # Hiperparámetros del modelo\n",
    "        lr_param = tf.placeholder(tf.float32, name = \"lr\")\n",
    "        lambda_param = tf.placeholder(tf.float32, name = \"lambda\")\n",
    "\n",
    "        # Coeficientes de regresión de logits, incluyendo intercepto\n",
    "        W = tf.Variable(tf.truncated_normal(shape = [k, 1]), name = \"W\")\n",
    "        b = tf.Variable(tf.truncated_normal(shape = (1, 1)), name = \"b\")\n",
    "        \n",
    "        # Logits de regresión multiple multiclase y pronóstico de clases\n",
    "        with tf.name_scope(\"Logits\"):\n",
    "            Logits = tf.add(tf.matmul(X, W), b, name = \"Logits\")\n",
    "            YlabelsHat = tf.nn.sigmoid(Logits)\n",
    "\n",
    "        # Función de costo\n",
    "        with tf.name_scope(\"FuncionCosto\"):\n",
    "            # Norma de los pesos\n",
    "            w_norm = tf.divide(tf.multiply(tf.multiply(tf.constant(0.5), lambda_param), \n",
    "                                 tf.reduce_sum(tf.square(W))), tf.cast(m, tf.float32), name = \"W_norm\")\n",
    "            # Costo por clasificación\n",
    "            classif_term = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels = Ylabels, logits = Logits), name = \"CostoClasif\") \n",
    "            # Costo total\n",
    "            cost = tf.add(classif_term, w_norm, name=\"Costo\")\n",
    "\n",
    "        # Gradient Descent Optimizer \n",
    "        with tf.name_scope(\"GradientDes.Optimizer\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(lr_param).minimize(cost) \n",
    "        \n",
    "        # Global Variables Initializer \n",
    "        init = tf.global_variables_initializer() \n",
    "        \n",
    "    # Entrenamiento del modelo\n",
    "    # -------------------------------------------------------------------------\n",
    "    start = time.time()\n",
    "    with tf.Session(graph = g) as sess:\n",
    "        \n",
    "        # Crear el objeto writer\n",
    "        #writer = tf.summary.FileWriter('./board/lr=%0.6f, C=%0.6f, epochs=%d, <%s>' % (lr, C, epochs, tag), sess.graph)\n",
    "        \n",
    "        # Inicializar variables\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Ejecutar batch gradient descent\n",
    "            _, c_ = sess.run([optimizer, cost], \n",
    "                             feed_dict = {X : Xtrain, Ylabels : Ytrain.reshape((m, 1)), \n",
    "                                          lr_param : lr, lambda_param : lambda_val})\n",
    "            \n",
    "            # Agregar summaries al tablero\n",
    "            #writer.add_summary(summ_, epoch + 1)\n",
    "            \n",
    "            if (epoch + 1) % round(epochs*0.1) == 0:\n",
    "                print(\"Epoch: %d, \\t costo = %0.4f\" % (epoch+1, c_))\n",
    "                \n",
    "        # Cerrar el writer del summary\n",
    "        #writer.close()\n",
    "                \n",
    "        # Obtener los parámetros finales para devolverlos\n",
    "        w_, b_ = sess.run([W, b])\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Tiempo transcurrido: %0.2f segundos\" % (end-start))\n",
    "    \n",
    "    # Devolver los parámetros\n",
    "    return w_, b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 20:16:31.581430 140316204836224 deprecation.py:323] From /home/alejo/anaconda3/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, \t costo = 1.6778\n",
      "Epoch: 200, \t costo = 1.2206\n",
      "Epoch: 300, \t costo = 1.2051\n",
      "Epoch: 400, \t costo = 1.1898\n",
      "Epoch: 500, \t costo = 1.1747\n",
      "Epoch: 600, \t costo = 1.1597\n",
      "Epoch: 700, \t costo = 1.1449\n",
      "Epoch: 800, \t costo = 1.1302\n",
      "Epoch: 900, \t costo = 1.1158\n",
      "Epoch: 1000, \t costo = 1.1014\n",
      "Tiempo transcurrido: 1.94 segundos\n"
     ]
    }
   ],
   "source": [
    "w_, b_ = entrenar_reg_logistica(X_train, y_train, lr = 0.001, epochs = 1000, lambda_val = 8., tag = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
